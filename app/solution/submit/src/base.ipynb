{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Library\n",
    "# ========================================\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "# import jpholiday\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import (\n",
    "    TimeSeriesSplit,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold,\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
    "from scipy.optimize import minimize\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_path = '../../train/'\n",
    "o_path = '../model/'\n",
    "\n",
    "TARGET = 'is_congestion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(i_path + 'train.csv')\n",
    "road_df = pd.read_csv(i_path + 'road_local.csv')\n",
    "search_spec_df = pd.read_csv(i_path + 'search_specified.csv')\n",
    "search_unspec_df = pd.read_csv(i_path + 'search_unspecified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_datetime(df):\n",
    "    if 'datetime' in df.columns:\n",
    "        df['year'] = df['datetime'].dt.year\n",
    "        df['month'] = df['datetime'].dt.month\n",
    "        df['day'] = df['datetime'].dt.day\n",
    "        df['hour'] = df['datetime'].dt.hour\n",
    "    if 'date' in df.columns:\n",
    "        df['year'] = df['date'].dt.year\n",
    "        df['month'] = df['date'].dt.month\n",
    "        df['day'] = df['date'].dt.day\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataset(train_df, search_spec_df, search_unspec_df):\n",
    "    train_df['datetime'] = pd.to_datetime(train_df['datetime'])\n",
    "    search_spec_df['datetime'] = pd.to_datetime(search_spec_df['datetime'])\n",
    "    search_unspec_df['date'] = pd.to_datetime(search_unspec_df['date'])\n",
    "\n",
    "    train_df = expand_datetime(train_df)\n",
    "    search_unspec_df = expand_datetime(search_unspec_df)\n",
    "\n",
    "    train_df = train_df.merge(search_spec_df, on=['datetime', 'start_code', 'end_code'], how='left')\n",
    "    train_df = train_df.merge(search_unspec_df, on=['year', 'month', 'day', 'start_code', 'end_code'], how='left')\n",
    "    train_df = train_df.merge(road_df.drop(['start_name', 'end_name'], axis=1), on=['start_code', 'end_code'], how='left')\n",
    "\n",
    "    train_df['dayofweek'] = train_df['datetime'].dt.weekday\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = extract_dataset(train_df, search_spec_df, search_unspec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['section'] = train['start_code'].astype(str) + '_' + train['KP'].astype(str) + '_' + train['end_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['road_code', 'start_code', 'end_code', 'section', 'direction', 'hour', 'dayofweek']\n",
    "num_cols = ['year', 'month', 'day', 'hour', 'search_specified', 'search_unspecified', 'KP', 'start_KP', 'end_KP', 'limit_speed', 'OCC']\n",
    "feature_cols = cat_cols + num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[feature_cols].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(X, y, cv,\n",
    "               model_path = [],\n",
    "               params: dict=None,\n",
    "               verbose: int=100\n",
    "               ):\n",
    "\n",
    "    # パラメータがないときは、空の dict で置き換える\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    models = []\n",
    "    n_records = len(X)\n",
    "    # training data の target と同じだけのゼロ配列を用意\n",
    "    oof_pred = np.zeros((n_records), dtype=np.float32)\n",
    "\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv):\n",
    "        x_train, y_train = X[idx_train], y[idx_train]\n",
    "        x_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "\n",
    "        clf = lgb.LGBMClassifier(**params)\n",
    "\n",
    "        clf.fit(x_train, y_train,\n",
    "                eval_set=[(x_valid, y_valid)],\n",
    "                callbacks=[\n",
    "                    lgb.early_stopping(stopping_rounds=50, verbose=True),\n",
    "                    lgb.log_evaluation(100)\n",
    "                ]\n",
    "                )\n",
    "\n",
    "        pred_i = clf.predict_proba(x_valid)[:,1]\n",
    "        oof_pred[idx_valid] = pred_i\n",
    "        models.append(clf)\n",
    "        score = roc_auc_score(y_valid, pred_i)\n",
    "        print(f\" - fold{i + 1} - {score:.4f}\")\n",
    "\n",
    "    score = roc_auc_score(y, oof_pred)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"FINISHI: CV Score: {score:.4f}\")\n",
    "    return score, oof_pred, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"n_estimators\": 100000,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"importance_type\": \"gain\",\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "# ========================================\n",
    "# train-validation split\n",
    "# ========================================\n",
    "N_SPLIT = 5\n",
    "kf = StratifiedGroupKFold(N_SPLIT)\n",
    "cv_list = list(kf.split(train, y=train[TARGET], groups=train['date']))\n",
    "\n",
    "# ========================================\n",
    "# define variables\n",
    "# ========================================\n",
    "X = train[feature_cols].values\n",
    "y = train[TARGET].values\n",
    "\n",
    "print('train shape:', train.shape)\n",
    "# ========================================\n",
    "# training\n",
    "# ========================================\n",
    "score, oof_pred, models = train_lgbm(X, y=y, params=params, cv=cv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#   params = {\n",
    "#       \"objective\": \"regression\",\n",
    "#       \"metric\": \"mae\",\n",
    "#       \"boosting_type\": \"rf\",\n",
    "#       \"verbosity\": -1,\n",
    "#       \"boost_from_average\": \"false\",\n",
    "#       \"random_seed\": 42,\n",
    "#       \"feature_pre_filter\": False,\n",
    "#       \"max_depth\": trial.suggest_int('max_depth', 4, 8),\n",
    "#       \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 100),\n",
    "#       \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1),\n",
    "#       \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.1, 1.0),\n",
    "#       \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.1, 1.0),\n",
    "#       \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 25),\n",
    "#       \"min_data_in_leaf\": trial.suggest_int('min_data_in_leaf', 1, 4)\n",
    "#       }\n",
    "\n",
    "#   model = lgb.train(params, train_set, valid_sets=[val_set])\n",
    "\n",
    "#   pred_y = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "#   f1 = f1_score(val_y, pred_y)\n",
    "\n",
    "#   return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction=\"maximum\")\n",
    "# study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適な閾値を探索\n",
    "\n",
    "def func(x_list, df, oof):\n",
    "    score = f1_score(df[TARGET], oof>x_list[0])\n",
    "    return -score\n",
    "\n",
    "x0 = [0.5]\n",
    "result = minimize(func, x0,  args=(train, oof_pred), method=\"nelder-mead\")\n",
    "threshold = result.x[0]\n",
    "train['pred'] = (oof_pred>threshold).astype(int)\n",
    "print('threshold:', threshold)\n",
    "print(classification_report(train[TARGET], train['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submit/model/model.pickle', mode='wb') as f:\n",
    "    pickle.dump(models,f,protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# feature importance\n",
    "# ========================================\n",
    "def visualize_importance(models, feat_train_df):\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    for i, model in enumerate(models):\n",
    "        _df = pd.DataFrame()\n",
    "        _df[\"feature_importance\"] = model.feature_importances_\n",
    "        _df[\"column\"] = feat_train_df.columns\n",
    "        _df[\"fold\"] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, _df],\n",
    "                                          axis=0, ignore_index=True)\n",
    "\n",
    "    order = feature_importance_df.groupby(\"column\")\\\n",
    "        .sum()[[\"feature_importance\"]]\\\n",
    "        .sort_values(\"feature_importance\", ascending=False).index\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, max(6, len(order) * .25)))\n",
    "    sns.boxplot(data=feature_importance_df,\n",
    "                  x=\"feature_importance\",\n",
    "                  y=\"column\",\n",
    "                  order=order,\n",
    "                  ax=ax,\n",
    "                  palette=\"viridis\",\n",
    "                  orient=\"h\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    ax.set_title(\"Importance\")\n",
    "    ax.grid()\n",
    "    fig.tight_layout()\n",
    "    return fig, ax, feature_importance_df\n",
    "\n",
    "fig, ax, feature_importance_df = visualize_importance(models, train[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
